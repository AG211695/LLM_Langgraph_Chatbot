{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRFOMTIv0tiN7yelQrYVwL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AG211695/LLM_Langgraph_Chatbot/blob/main/ChatBot_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cALzMBE8Kvzy",
        "outputId": "71422e32-e76e-4492-81d7-98401cf1bdf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.1.104)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.2.35)\n",
            "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith) (3.10.7)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.0.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.27->langgraph) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7LONxeZLwaX",
        "outputId": "31cf7542-294f-420d-e15c-b6c075f07948"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.35)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.104)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.9.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api_key')\n",
        "langsmith = userdata.get('langsmith_api_key')"
      ],
      "metadata": {
        "id": "H9OjO7xnLwXK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]= langsmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"ChatBotLanggraph\""
      ],
      "metadata": {
        "id": "gvh_oW7ELwVA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "HVLlBhGmLwTG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model=ChatGroq(groq_api_key=groq_api_key,model_name='llama-3.1-70b-versatile')\n",
        "llm_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaEFvS4GLvuw",
        "outputId": "730de7ef-c9b0-4a72-ae6d-7aa2fa717691"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7e9a33ce9fc0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7e9a33ce92d0>, model_name='llama-3.1-70b-versatile', groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**So far all the necessary connections and imports have been made. Now, using Langgraph, building of ChatbBot Begins**"
      ],
      "metadata": {
        "id": "YDwqZbmKSBOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "xcrRb1uiR2IE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "graph_builder=StateGraph(State)"
      ],
      "metadata": {
        "id": "FjzTy29nR2KV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4-hfAEPR2Mo",
        "outputId": "6174e19f-2923-42f6-9759-8249a5f1eaf2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e9a33ce8a60>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to make the chatbot to interact with LLM\n",
        "# In this case it's going to interact with latest Llama 3\n",
        "\n",
        "def chatbot(state:State):\n",
        "  return {\"messages\":llm_model.invoke(state['messages'])}"
      ],
      "metadata": {
        "id": "is1Y5XP5R2O2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ],
      "metadata": {
        "id": "bsqVyK5ER2RO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnu-0RdtR2Tk",
        "outputId": "402bd9b7-a85d-41e7-af81-c11b1fd052ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e9a33ce8a60>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connecting nodes to chatbot and creating start -- Chatbot -- end flow\n",
        "graph_builder.add_edge(START,'chatbot')\n",
        "graph_builder.add_edge('chatbot',END)"
      ],
      "metadata": {
        "id": "OOjhQeW8R2Vr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling graph_builder\n",
        "graph=graph_builder.compile()"
      ],
      "metadata": {
        "id": "OWVeq-kYR2ZK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the flow\n",
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid.png()))\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "id": "uulpkbY_1Yl3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Executing, using the chatbot\n",
        "while True:\n",
        "  user_input=input(\"User: \")\n",
        "  if user_input.lower() in ['quit','q']:\n",
        "    print('Good Bye!')\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      print('Assistant:',value['messages'].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqSLZxyE1YoV",
        "outputId": "b4f2d232-2753-4140-ea6f-6621bd4b20a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: hi\n",
            "dict_values([{'messages': AIMessage(content='How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 36, 'total_tokens': 44, 'completion_time': 0.032, 'prompt_time': 0.009145294, 'queue_time': 0.005426725, 'total_time': 0.041145294}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'stop', 'logprobs': None}, id='run-0079e3ae-7a5e-4be4-9f78-a71dbcd91b3b-0', usage_metadata={'input_tokens': 36, 'output_tokens': 8, 'total_tokens': 44})}])\n",
            "content='How can I assist you today?' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 36, 'total_tokens': 44, 'completion_time': 0.032, 'prompt_time': 0.009145294, 'queue_time': 0.005426725, 'total_time': 0.041145294}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'stop', 'logprobs': None} id='run-0079e3ae-7a5e-4be4-9f78-a71dbcd91b3b-0' usage_metadata={'input_tokens': 36, 'output_tokens': 8, 'total_tokens': 44}\n",
            "Assistant: How can I assist you today?\n",
            "User: List me the skillset needed for an AI engineer\n",
            "dict_values([{'messages': AIMessage(content=\"Here's a comprehensive list of the skillset needed for an AI engineer:\\n\\n**Core Skills:**\\n\\n1. **Programming languages**: Proficiency in languages such as Python, Java, C++, and R.\\n2. **Mathematics**: Strong understanding of mathematical concepts like linear algebra, calculus, probability, and statistics.\\n3. **Data structures and algorithms**: Knowledge of data structures like arrays, linked lists, trees, and graphs, as well as algorithms like sorting, searching, and optimization.\\n4. **Machine learning**: Familiarity with machine learning concepts like supervised and unsupervised learning, regression, classification, clustering, and neural networks.\\n5. **Deep learning**: Understanding of deep learning concepts like convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory (LSTM) networks.\\n\\n**AI-specific Skills:**\\n\\n1. **Computer vision**: Knowledge of computer vision concepts like image processing, object detection, and image classification.\\n2. **Natural Language Processing (NLP)**: Understanding of NLP concepts like text processing, sentiment analysis, and language modeling.\\n3. **Robotics**: Familiarity with robotics concepts like robotic arms, computer vision, and machine learning.\\n4. **Expert systems**: Knowledge of expert systems concepts like knowledge representation, inference engines, and decision-making.\\n5. **Neural networks**: Understanding of neural network concepts like feedforward networks, backpropagation, and activation functions.\\n\\n**Software and Tools:**\\n\\n1. **TensorFlow**: Familiarity with TensorFlow, a popular open-source machine learning framework.\\n2. **PyTorch**: Knowledge of PyTorch, a popular open-source machine learning framework.\\n3. **Keras**: Understanding of Keras, a high-level neural networks API.\\n4. **OpenCV**: Familiarity with OpenCV, a computer vision library.\\n5. **NLTK**: Knowledge of NLTK, a natural language processing library.\\n6. **Scikit-learn**: Understanding of Scikit-learn, a machine learning library.\\n7. **Cloud platforms**: Familiarity with cloud platforms like AWS, Google Cloud, or Azure.\\n\\n**Soft Skills:**\\n\\n1. **Communication**: Ability to communicate complex technical concepts to non-technical stakeholders.\\n2. **Collaboration**: Ability to work with cross-functional teams, including data scientists, engineers, and product managers.\\n3. **Problem-solving**: Ability to identify and solve complex problems.\\n4. **Adaptability**: Ability to adapt to new technologies and frameworks.\\n5. **Continuous learning**: Commitment to ongoing learning and professional development.\\n\\n**Education and Certifications:**\\n\\n1. **Bachelor's or Master's degree**: In computer science, mathematics, or a related field.\\n2. **Certifications**: Consider obtaining certifications like Certified Data Scientist (CDS) or Certified AI Engineer (CAIE).\\n\\nNote that the specific skillset required may vary depending on the organization, role, and industry.\", response_metadata={'token_usage': {'completion_tokens': 599, 'prompt_tokens': 45, 'total_tokens': 644, 'completion_time': 2.396, 'prompt_time': 0.010980584, 'queue_time': 0.004823282999999999, 'total_time': 2.406980584}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'stop', 'logprobs': None}, id='run-fe884643-1094-463e-8fc0-8cb5340988a2-0', usage_metadata={'input_tokens': 45, 'output_tokens': 599, 'total_tokens': 644})}])\n",
            "content=\"Here's a comprehensive list of the skillset needed for an AI engineer:\\n\\n**Core Skills:**\\n\\n1. **Programming languages**: Proficiency in languages such as Python, Java, C++, and R.\\n2. **Mathematics**: Strong understanding of mathematical concepts like linear algebra, calculus, probability, and statistics.\\n3. **Data structures and algorithms**: Knowledge of data structures like arrays, linked lists, trees, and graphs, as well as algorithms like sorting, searching, and optimization.\\n4. **Machine learning**: Familiarity with machine learning concepts like supervised and unsupervised learning, regression, classification, clustering, and neural networks.\\n5. **Deep learning**: Understanding of deep learning concepts like convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory (LSTM) networks.\\n\\n**AI-specific Skills:**\\n\\n1. **Computer vision**: Knowledge of computer vision concepts like image processing, object detection, and image classification.\\n2. **Natural Language Processing (NLP)**: Understanding of NLP concepts like text processing, sentiment analysis, and language modeling.\\n3. **Robotics**: Familiarity with robotics concepts like robotic arms, computer vision, and machine learning.\\n4. **Expert systems**: Knowledge of expert systems concepts like knowledge representation, inference engines, and decision-making.\\n5. **Neural networks**: Understanding of neural network concepts like feedforward networks, backpropagation, and activation functions.\\n\\n**Software and Tools:**\\n\\n1. **TensorFlow**: Familiarity with TensorFlow, a popular open-source machine learning framework.\\n2. **PyTorch**: Knowledge of PyTorch, a popular open-source machine learning framework.\\n3. **Keras**: Understanding of Keras, a high-level neural networks API.\\n4. **OpenCV**: Familiarity with OpenCV, a computer vision library.\\n5. **NLTK**: Knowledge of NLTK, a natural language processing library.\\n6. **Scikit-learn**: Understanding of Scikit-learn, a machine learning library.\\n7. **Cloud platforms**: Familiarity with cloud platforms like AWS, Google Cloud, or Azure.\\n\\n**Soft Skills:**\\n\\n1. **Communication**: Ability to communicate complex technical concepts to non-technical stakeholders.\\n2. **Collaboration**: Ability to work with cross-functional teams, including data scientists, engineers, and product managers.\\n3. **Problem-solving**: Ability to identify and solve complex problems.\\n4. **Adaptability**: Ability to adapt to new technologies and frameworks.\\n5. **Continuous learning**: Commitment to ongoing learning and professional development.\\n\\n**Education and Certifications:**\\n\\n1. **Bachelor's or Master's degree**: In computer science, mathematics, or a related field.\\n2. **Certifications**: Consider obtaining certifications like Certified Data Scientist (CDS) or Certified AI Engineer (CAIE).\\n\\nNote that the specific skillset required may vary depending on the organization, role, and industry.\" response_metadata={'token_usage': {'completion_tokens': 599, 'prompt_tokens': 45, 'total_tokens': 644, 'completion_time': 2.396, 'prompt_time': 0.010980584, 'queue_time': 0.004823282999999999, 'total_time': 2.406980584}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'stop', 'logprobs': None} id='run-fe884643-1094-463e-8fc0-8cb5340988a2-0' usage_metadata={'input_tokens': 45, 'output_tokens': 599, 'total_tokens': 644}\n",
            "Assistant: Here's a comprehensive list of the skillset needed for an AI engineer:\n",
            "\n",
            "**Core Skills:**\n",
            "\n",
            "1. **Programming languages**: Proficiency in languages such as Python, Java, C++, and R.\n",
            "2. **Mathematics**: Strong understanding of mathematical concepts like linear algebra, calculus, probability, and statistics.\n",
            "3. **Data structures and algorithms**: Knowledge of data structures like arrays, linked lists, trees, and graphs, as well as algorithms like sorting, searching, and optimization.\n",
            "4. **Machine learning**: Familiarity with machine learning concepts like supervised and unsupervised learning, regression, classification, clustering, and neural networks.\n",
            "5. **Deep learning**: Understanding of deep learning concepts like convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory (LSTM) networks.\n",
            "\n",
            "**AI-specific Skills:**\n",
            "\n",
            "1. **Computer vision**: Knowledge of computer vision concepts like image processing, object detection, and image classification.\n",
            "2. **Natural Language Processing (NLP)**: Understanding of NLP concepts like text processing, sentiment analysis, and language modeling.\n",
            "3. **Robotics**: Familiarity with robotics concepts like robotic arms, computer vision, and machine learning.\n",
            "4. **Expert systems**: Knowledge of expert systems concepts like knowledge representation, inference engines, and decision-making.\n",
            "5. **Neural networks**: Understanding of neural network concepts like feedforward networks, backpropagation, and activation functions.\n",
            "\n",
            "**Software and Tools:**\n",
            "\n",
            "1. **TensorFlow**: Familiarity with TensorFlow, a popular open-source machine learning framework.\n",
            "2. **PyTorch**: Knowledge of PyTorch, a popular open-source machine learning framework.\n",
            "3. **Keras**: Understanding of Keras, a high-level neural networks API.\n",
            "4. **OpenCV**: Familiarity with OpenCV, a computer vision library.\n",
            "5. **NLTK**: Knowledge of NLTK, a natural language processing library.\n",
            "6. **Scikit-learn**: Understanding of Scikit-learn, a machine learning library.\n",
            "7. **Cloud platforms**: Familiarity with cloud platforms like AWS, Google Cloud, or Azure.\n",
            "\n",
            "**Soft Skills:**\n",
            "\n",
            "1. **Communication**: Ability to communicate complex technical concepts to non-technical stakeholders.\n",
            "2. **Collaboration**: Ability to work with cross-functional teams, including data scientists, engineers, and product managers.\n",
            "3. **Problem-solving**: Ability to identify and solve complex problems.\n",
            "4. **Adaptability**: Ability to adapt to new technologies and frameworks.\n",
            "5. **Continuous learning**: Commitment to ongoing learning and professional development.\n",
            "\n",
            "**Education and Certifications:**\n",
            "\n",
            "1. **Bachelor's or Master's degree**: In computer science, mathematics, or a related field.\n",
            "2. **Certifications**: Consider obtaining certifications like Certified Data Scientist (CDS) or Certified AI Engineer (CAIE).\n",
            "\n",
            "Note that the specific skillset required may vary depending on the organization, role, and industry.\n",
            "User: q\n",
            "Good Bye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dks6DByb1Yr7"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}